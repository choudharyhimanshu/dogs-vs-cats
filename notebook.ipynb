{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dogs vs Cats Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Problem Statement</b>: The train folder contains 25,000 images of dogs and cats. Each image in this folder has the label as part of the filename. The test folder contains 12,500 images, named according to a numeric id. For each image in the test set, you should predict a probability that the image is a dog (1 = dog, 0 = cat)."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "@author: Himanshu Choudhary\n",
    "@git: https://github.com/choudharyhimanshu/\n",
    "@email: developer.himnshu@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from os import listdir\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "DIR_DATASET_ROOT = \"dataset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "files = listdir(DIR_DATASET_ROOT+\"train/\")\n",
    "files = np.random.choice(files,50)   # choose any random N images\n",
    "\n",
    "data = []\n",
    "for file in files:\n",
    "    img = cv2.cvtColor(cv2.imread(DIR_DATASET_ROOT+\"train/\"+file),cv2.COLOR_BGR2GRAY)\n",
    "    if \"dog\" in file:\n",
    "        data.append((file.split('.')[1],img,0))\n",
    "    else:\n",
    "        data.append((file.split('.')[1],img,1))\n",
    "\n",
    "df = pd.DataFrame(data,columns=[\"ID\",\"img\",\"label\"]).set_index([\"ID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "def get_descriptors(img):\n",
    "    return (sift.detectAndCompute(img,None))[1]\n",
    "\n",
    "df[\"descriptors\"] = df[\"img\"].map(get_descriptors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = []\n",
    "for index,row in df.iterrows():\n",
    "    for desc in row.descriptors:\n",
    "        features.append((desc,row.label,index))\n",
    "\n",
    "features = pd.DataFrame(features,columns=[\"descriptor\",\"label\",\"fk_ID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i,row in features.iterrows():\n",
    "    X.append(np.array(row.descriptor))\n",
    "    y.append(np.array(row.label))\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential Neural Network with Dense layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn = Sequential()\n",
    "nn.add(Dense(128,input_dim=128,init='normal',activation=\"tanh\"))\n",
    "nn.add(Dense(1,init='normal',activation=\"sigmoid\"))\n",
    "nn.compile(loss=\"binary_crossentropy\",optimizer='sgd', metrics=['accuracy'])\n",
    "nn.summary()\n",
    "nn.fit(X_train,y_train,verbose=1,nb_epoch=10,batch_size=32)\n",
    "nn.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
